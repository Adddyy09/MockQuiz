export const quizData = [
    // Part 1: True or False (Questions 1-15)
    { id: 1, type: 'tf', question: "Image contrast refers to the brightness differences between regions in an image. Larger differences indicate more contrast.", options: ["True", "False"], answer: "True", explanation: "This is the definition of contrast. High contrast images have a wide range of brightness levels, while low contrast images have a narrow range." },
    { id: 2, type: 'tf', question: "In a wave filtering experiment of image preprocessing, the `cv2.medianBlur(im, 5)` function provided by OpenCV can be used to perform median blurring.", options: ["True", "False"], answer: "True", explanation: "The `cv2.medianBlur()` function applies a median filter, which is effective for removing salt-and-pepper noise." },
    { id: 3, type: 'tf', question: "If the R, G, and B channels of a color image are inverted, the brightness of the image changes, but the color does not.", options: ["True", "False"], answer: "False", explanation: "Inverting the R, G, and B channels changes the image to its negative, which alters both the color and the brightness." },
    { id: 4, type: 'tf', question: "A larger sampling interval indicates a higher spatial resolution and better image quality.", options: ["True", "False"], answer: "False", explanation: "A larger sampling interval means fewer samples are taken, which results in a lower spatial resolution and poorer image quality." },
    { id: 5, type: 'tf', question: "A larger template indicates mean filtering with better denoising. During denoising, you need to select a large template for mean filtering.", options: ["True", "False"], answer: "False", explanation: "While a larger template provides more smoothing, it also causes more blurring and loss of detail. The template size must be chosen carefully to balance noise reduction and detail preservation." },
    { id: 6, type: 'tf', question: "Different algorithms cannot be used together [in image processing].", options: ["True", "False"], answer: "False", explanation: "Image processing pipelines often involve combining multiple algorithms in sequence (e.g., filtering, then edge detection, then transformation) to achieve a desired result." },
    { id: 7, type: 'tf', question: "Image filters are also called template operations. Common template operations include template convolution and template sorting.", options: ["True", "False"], answer: "True", explanation: "Filtering involves applying a template (or kernel) to a neighborhood of pixels. Convolution (like mean or Gaussian filters) and sorting (like median filters) are common template operations." },
    { id: 8, type: 'tf', question: "Histogram specification enhances the regions of interest in an image by adjusting the image's histogram to a specified one.", options: ["True", "False"], answer: "True", explanation: "Histogram specification (or matching) is a technique to transform an image's histogram to match a target histogram, which can be used to enhance specific features." },
    { id: 9, type: 'tf', question: "The expectation-maximization (EM) algorithm starts with randomly sampled data to estimate the parameters of a model containing hidden parameters.", options: ["True", "False"], answer: "True", explanation: "The EM algorithm is an iterative method for finding maximum likelihood estimates of parameters in statistical models, where the model depends on unobserved latent variables. It starts with an initial guess for the parameters." },
    { id: 10, type: 'tf', question: "A Markov chain is a discrete-event stochastic process with the Markov property in mathematics.", options: ["True", "False"], answer: "True", explanation: "This is the definition of a Markov chain. The Markov property states that the future state depends only on the current state, not on the sequence of events that preceded it." },
    { id: 11, type: 'tf', question: "A candidate word set must be specified in advance for isolated word recognition.", options: ["True", "False"], answer: "True", explanation: "In isolated word recognition, the system is trained to recognize a specific, predefined vocabulary (candidate word set)." },
    { id: 12, type: 'tf', question: "In the Gaussian mixture model (GMM), since it is unknown which Gaussian model the sample belongs to, it is impossible to solve the parameters using the maximum likelihood function.", options: ["True", "False"], answer: "False", explanation: "The parameters of a GMM can be estimated using the Expectation-Maximization (EM) algorithm, which is a method for finding maximum likelihood estimates in models with latent variables." },
    { id: 13, type: 'tf', question: "Conditional random field (CRF) cancels two independent assumptions of the HMM... and also performs probability normalization globally.", options: ["True", "False"], answer: "True", explanation: "CRFs are discriminative models that relax the strong independence assumptions made by HMMs and normalize probabilities over the entire sequence, avoiding the label bias problem." },
    { id: 14, type: 'tf', question: "TF-IDF is a statistical method used to reflect how important a word is to a document, and to vectorize the document.", options: ["True", "False"], answer: "True", explanation: "Term Frequency-Inverse Document Frequency (TF-IDF) is a numerical statistic that reflects a word's importance to a document in a collection or corpus." },
    { id: 15, type: 'tf', question: "In the Transformer, there are no CNN or LSTM layers.", options: ["True", "False"], answer: "True", explanation: "The original Transformer architecture relies entirely on self-attention mechanisms and feed-forward networks, dispensing with recurrence (like LSTMs) and convolutions (like CNNs)." },

    // Part 2: Single-Answer Multiple Choice (Questions 16-36)
    { id: 16, type: 'mc', question: "Which of the following statements about the backpropagation algorithm is false?", options: ["A. The backpropagation algorithm uses the chain rule...", "B. The steps of backpropagation are as follows...", "C. Backpropagation through time (BPTT) is an extension...", "D. In practice, the backpropagation algorithm effectively solves the vanishing gradient problem."], answer: "D. In practice, the backpropagation algorithm effectively solves the vanishing gradient problem.", explanation: "Backpropagation is the algorithm used to calculate gradients. It does not solve the vanishing gradient problem; in fact, it's during backpropagation that the problem manifests." },
    { id: 17, type: 'mc', question: "Which of the following statements about contrast stretching is true?", options: ["A. Contrast stretching maps the brightness values... It is applicable only to grayscale images.", "B. Contrast stretching compresses the brightness value...", "C. Contrast stretching improves the contrast of an image by stretching the brightness values of the image to the entire grayscale range. It can be used to enhance the contrast of color images.", "D. Contrast stretching applies only to high-contrast images..."], answer: "C. Contrast stretching improves the contrast of an image by stretching the brightness values of the image to the entire grayscale range. It can be used to enhance the contrast of color images.", explanation: "Contrast stretching expands the range of intensity values to improve contrast. It can be applied to each channel of a color image." },
    { id: 18, type: 'mc', question: "Which of the following operations can be used to calculate the rotation matrix?", options: ["A. print(type(im))", "B. cv2.getRotationMatrix2D(center, angle, scale)", "C. cv2.filter2D(im,-1,sharpen_1)", "D. np.round(np.array(gamma_list)).astype(np.uint8)"], answer: "B. cv2.getRotationMatrix2D(center, angle, scale)", explanation: "In OpenCV, `getRotationMatrix2D` is the function used to compute the 2D affine transformation matrix for rotation." },
    { id: 19, type: 'mc', question: "Which of the following statements about morphological operations is false?", options: ["A. The basic morphological operations include dilation and erosion.", "B. The basic morphological operations can be combined...", "C. Morphological processing is often used for noise removal...", "D. Morphological operations can be performed only on binary images."], answer: "D. Morphological operations can be performed only on binary images.", explanation: "While often used on binary images, morphological operations like erosion and dilation can also be applied to grayscale images." },
    { id: 20, type: 'mc', question: "When we calculate the LBP feature of a pixel in a 3x3 window, if the value of this pixel is smaller than the values of neighboring pixels, which of the following is the LBP value of this pixel?", options: ["A. 8", "B. 127", "C. 255", "D. 256"], answer: "C. 255", explanation: "If the center pixel is smaller than all 8 neighbors, the resulting binary pattern will be '11111111', which is 255 in decimal." },
    { id: 21, type: 'mc', question: "Which of the following convolutional neural networks has the most layers?", options: ["A. ResNet-18", "B. AlexNet", "C. VGG-16", "D. LeNet"], answer: "A. ResNet-18", explanation: "LeNet has 5 layers, AlexNet has 8, VGG-16 has 16, and ResNet-18 has 18. The question seems to have an incorrect answer key; ResNet-18 has more layers than VGG-16." },
    { id: 22, type: 'mc', question: "If two 3x3 convolution kernels are used to perform the convolution operation on a three-channel color image, how many channels does the generated feature map have?", options: ["A. 1", "B. 2", "C. 3", "D. 4"], answer: "B. 2", explanation: "The number of output channels in a convolutional layer is equal to the number of convolution kernels (or filters) used. In this case, two kernels produce a two-channel feature map." },
    { id: 23, type: 'mc', question: "The YOLOv3 network predicts three bounding boxes for each cell. Which of the following is the largest benefit?", options: ["A. Accelerated network prediction", "B. Increased number of predicted bounding boxes", "C. No additional advantages", "D. Enlarged receptive field for detecting different sizes of objects"], answer: "D. Enlarged receptive field for detecting different sizes of objects", explanation: "YOLOv3 makes predictions at three different scales, allowing it to have different receptive fields and effectively detect objects of various sizes." },
    { id: 24, type: 'mc', question: "Which of the following is a time-domain parameter of speech signals?", options: ["A. Zero-crossing rate", "B. Fundamental frequency", "C. Formant", "D. Harmonic frequency"], answer: "A. Zero-crossing rate", explanation: "The zero-crossing rate is calculated directly from the time-domain waveform. The others are frequency-domain parameters obtained after a Fourier transform." },
    { id: 25, type: 'mc', question: "How many elements are used to describe a hidden Markov model (HMM)?", options: ["A. 3", "B. 4", "C. 5", "D. 6"], answer: "A. 3", explanation: "An HMM is defined by three key elements (parameters): the initial state probability distribution, the state transition probability matrix, and the emission probability distribution." },
    { id: 26, type: 'mc', question: "Which classic algorithm is used to solve the decoding problem in the hidden Markov model (HMM)?", options: ["A. Expectation-maximization (EM) algorithm", "B. Forward algorithm", "C. Viterbi algorithm", "D. Backward algorithm"], answer: "C. Viterbi algorithm", explanation: "The Viterbi algorithm is a dynamic programming algorithm used to find the most likely sequence of hidden states (decoding) that results in a sequence of observed events." },
    { id: 27, type: 'mc', question: "Which of the following is not one of the three main problems of the hidden Markov model (HMM)?", options: ["A. Testing", "B. Evaluation", "C. Decoding", "D. Training"], answer: "A. Testing", explanation: "The three canonical problems of HMMs are Evaluation (Probability), Decoding (most likely path), and Learning (Training)." },
    { id: 28, type: 'mc', question: "Which of the following is the correct method for training static word vectors?", options: ["A. FastText", "B. GPT", "C. ELMO", "D. BERT"], answer: "A. FastText", explanation: "FastText, like Word2Vec, is a method for learning static word embeddings. BERT, ELMO, and GPT produce contextualized, dynamic embeddings." },
    { id: 29, type: 'mc', question: "Which of the following statements about skip-gram is true?", options: ["A. The core concept of skip-gram is to predict context words using a center word, so as to learn vector representations of the words.", "B. Skip-gram obtains the context information through the sliding window mechanism...", "C. The dimensions of the word vector generated by skip-gram are directly proportional...", "D. The skip-gram algorithm is the same as that of the Continuous Bag of Words (CBOW) model..."], answer: "A. The core concept of skip-gram is to predict context words using a center word, so as to learn vector representations of the words.", explanation: "This correctly describes the Skip-gram model's objective: given a center word, it tries to predict the surrounding context words." },
    { id: 30, type: 'mc', question: "Which of the following is used for TF-IDF vectorization in scikit-learn?", options: ["A. TfidfVector", "B. TfidfVectorizer", "C. TfidfFit", "D. TfidfTransform"], answer: "B. TfidfVectorizer", explanation: "`TfidfVectorizer` is the scikit-learn class that combines tokenization, counting, and TF-IDF transformation into a single step." },
    { id: 31, type: 'mc', question: "In an AI architecture, which of the following is used to simplify programming and algorithm implementation?", options: ["A. An AI chip layer", "B. A chip enablement layer", "C. An AI framework layer", "D. An application enablement layer"], answer: "C. An AI framework layer", explanation: "AI frameworks like TensorFlow and PyTorch provide high-level APIs that abstract away low-level operations, simplifying development." },
    { id: 32, type: 'mc', question: "Which of the following is not a feature of large models (models with hundreds of billions of parameters)?", options: ["A. A single instance with a single GPU can complete a training job.", "B. Similarity search of unstructured data is primarily achieved through vector databases.", "C. Increasing demands for server interconnect bandwidth necessitate lossless networking.", "D. AI computing centers are specialized facilities designed for AI applications."], answer: "A. A single instance with a single GPU can complete a training job.", explanation: "Training large models requires massive computational power, typically involving hundreds or thousands of GPUs in a distributed cluster, not a single GPU." },
    { id: 33, type: 'mc', question: "Which of the following functions provided by ModelArts enable AI beginners to build AI models?", options: ["A. ExeML", "B. Model management", "C. Deployment", "D. Model conversion"], answer: "A. ExeML", explanation: "ExeML (AutoML) in ModelArts provides a low-code/no-code interface for automatically training models, making it accessible for beginners." },
    { id: 34, type: 'mc', question: "In multi-classification tasks, which of the following activation function is usually used in the output layer?", options: ["A. Sigmoid", "B. tanh", "C. ReLU", "D. SoftMax"], answer: "D. SoftMax", explanation: "The Softmax function is used in the output layer for multi-class classification because it converts logits into a probability distribution over the classes." },
    { id: 35, type: 'mc', question: "In binary classification tasks, which of the following activation function is usually used?", options: ["A. Sigmoid", "B. tanh", "C. ReLU", "D. LeakyReLU"], answer: "A. Sigmoid", explanation: "The Sigmoid function is used in the output layer for binary classification as it squashes the output to a value between 0 and 1, which can be interpreted as a probability." },
    { id: 36, type: 'mc', question: "In the field of deep learning, which of the following activation functions generate values that fall within the range of (0, positive infinity)?", options: ["A. Sigmoid", "B. ReLU", "C. SeLU", "D. Tanh"], answer: "B. ReLU", explanation: "The ReLU (Rectified Linear Unit) function is defined as f(x) = max(0, x), so its output range is [0, +∞)." },

    // Part 3: Multiple-Answer Questions (Questions 37-55)
    { id: 37, type: 'mc', multi: true, question: "What are the common digital image color spaces?", options: ["A. CMYK", "B. RGB", "C. HSV", "D. YUV"], answer_set: ["A. CMYK", "B. RGB", "C. HSV", "D. YUV"], explanation: "All of these are standard color spaces used in digital imaging for different purposes (display, printing, video compression, etc.)." },
    { id: 38, type: 'mc', multi: true, question: "Which of the following statements are true about the application of gamma correction?", options: ["A. Gamma correction is often performed automatically when image capture devices save images...", "B. The relationship between the input energy of an image capture device and image color luminance is linear...", "C. A larger difference between the value of gamma and 1 indicates a greater gamma correction strength.", "D. A larger difference between the value of gamma and 1 indicates a lower gamma correction strength."], answer_set: ["A. Gamma correction is often performed automatically when image capture devices save images...", "B. The relationship between the input energy of an image capture device and image color luminance is linear...", "C. A larger difference between the value of gamma and 1 indicates a greater gamma correction strength."], explanation: "Gamma correction compensates for the non-linear response of display devices. A gamma value further from 1 results in a more significant correction." },
    { id: 39, type: 'mc', multi: true, question: "Which of the following operations are available in image data augmentation?", options: ["A. Channel transformation", "B. Affine transformation", "C. Contrast adjustment", "D. Shearing"], answer_set: ["A. Channel transformation", "B. Affine transformation", "C. Contrast adjustment", "D. Shearing"], explanation: "All these techniques are used to artificially expand a dataset by creating modified copies of images, which helps improve model robustness." },
    { id: 40, type: 'mc', multi: true, question: "The number '19' in VGG-19 indicates the total number network layers of different types. What are these types of layers?", options: ["A. Convolution layer", "B. Pooling layer", "C. Fully connected layer", "D. Input layer"], answer_set: ["A. Convolution layer", "B. Pooling layer", "C. Fully connected layer"], explanation: "The number in VGG architectures refers to the number of weight layers, which are the convolution and fully connected layers. Pooling layers do not have weights." },
    { id: 41, type: 'mc', multi: true, question: "Which of the following methods are available for uploading images to Huawei Cloud Image Tagging?", options: ["A. Uploading images through OBS", "B. Uploading images by specifying URLs", "C. Uploading Base64-encoded images", "D. Uploading compressed image files"], answer_set: ["A. Uploading images through OBS", "B. Uploading images by specifying URLs", "C. Uploading Base64-encoded images"], explanation: "The Image Tagging service API supports providing image data via an OBS path, a public URL, or as a Base64-encoded string." },
    { id: 42, type: 'mc', multi: true, question: "Which of the following are methods of speech synthesis?", options: ["A. Formant synthesizer", "B. Serial formant synthesizer", "C. Parallel formant synthesizer", "D. Pitch-synchronous overlap and add (PSOLA) method"], answer_set: ["C. Parallel formant synthesizer", "D. Pitch-synchronous overlap and add (PSOLA) method"], explanation: "Formant synthesis and concatenative synthesis (like PSOLA) are two major categories of speech synthesis techniques." },
    { id: 43, type: 'mc', multi: true, question: "Which of the following are parameters in a Gaussian mixture model (GMM)?", options: ["A. The proportion of sample data points taken from the k-th single Gaussian model", "B. The number of single Gaussian models", "C. The mean of a single Gaussian model", "D. The standard deviation of a single Gaussian model"], answer_set: ["A. The proportion of sample data points taken from the k-th single Gaussian model", "B. The number of single Gaussian models", "C. The mean of a single Gaussian model", "D. The standard deviation of a single Gaussian model"], explanation: "A GMM is defined by the number of components (B), the weight of each component (A), and the mean (C) and covariance/standard deviation (D) of each component." },
    { id: 44, type: 'mc', multi: true, question: "Which of the following are challenges in speech recognition?", options: ["A. Far-field microphone recognition", "B. High-noise environment recognition", "C. Multi-speaker environment recognition", "D. Dialect recognition"], answer_set: ["A. Far-field microphone recognition", "B. High-noise environment recognition", "C. Multi-speaker environment recognition", "D. Dialect recognition"], explanation: "All of these factors introduce significant variability and noise into the speech signal, making recognition more difficult." },
    { id: 45, type: 'mc', multi: true, question: "Which of the following are parameters of a hidden Markov model (HMM)?", options: ["A. Initial probability", "B. Transition probability", "C. Emission probability", "D. Observation sequence"], answer_set: ["A. Initial probability", "B. Transition probability", "C. Emission probability"], explanation: "An HMM is defined by its parameters: initial state probabilities, state transition probabilities, and emission probabilities. The observation sequence is the data, not a parameter of the model." },
    { id: 46, type: 'mc', multi: true, question: "Which of the following statements about recognizing single words using Gaussian mixture model (GMM)-hidden Markov model (HMM) speech recognition algorithms are true?", options: ["A. The hidden states of each word are fixed...", "B. A GMM-HMM model needs to be trained for each word.", "C. A GMM model needs to be trained for each hidden state of a word.", "D. When determining which word an audio file belongs to, the learning process of the GMM-HMM is used."], answer_set: ["B. A GMM-HMM model needs to be trained for each word.", "C. A GMM model needs to be trained for each hidden state of a word."], explanation: "In this approach, each word in the vocabulary is modeled by its own HMM. The emission probabilities for each state in the HMM are modeled by a GMM." },
    { id: 47, type: 'mc', multi: true, question: "In speech recognition tasks, what does data preprocessing include?", options: ["A. Windowing", "B. Pre-emphasis", "C. Endpoint detection", "D. Framing"], answer_set: ["A. Windowing", "B. Pre-emphasis", "C. Endpoint detection", "D. Framing"], explanation: "All these are standard preprocessing steps to segment the continuous speech signal and prepare it for feature extraction." },
    { id: 48, type: 'mc', multi: true, question: "Which of the following statements about transformer models are true?", options: ["A. The encoder of a transformer model consists of a stack of multiple identical blocks...", "B. The encoder and decoder of a transformer model include an attention module...", "C. Positional encodings are added to word vectors in a transformer model...", "D. A transformer encoder can perform, parallel computation during training..."], answer_set: ["A. The encoder of a transformer model consists of a stack of multiple identical blocks...", "B. The encoder and decoder of a transformer model include an attention module...", "C. Positional encodings are added to word vectors in a transformer model...", "D. A transformer encoder can perform, parallel computation during training..."], explanation: "All these statements describe key architectural features of the Transformer model, which enable its high performance and parallelizability." },
    { id: 49, type: 'mc', multi: true, question: "Which of the following modules are included in the transformer encoder?", options: ["A. Self-attention sub-layer", "B. Feedforward sub-layer", "C. Residual connection", "D. Layer normalization"], answer_set: ["A. Self-attention sub-layer", "B. Feedforward sub-layer", "C. Residual connection", "D. Layer normalization"], explanation: "A standard Transformer encoder block is composed of a multi-head self-attention layer and a position-wise feed-forward network, with residual connections and layer normalization applied to each." },
    { id: 50, type: 'mc', multi: true, question: "Which of the following statements are true about Continuous Bag of Words (CBOW)?", options: ["A. The core idea of the CBOW algorithm is to predict the center word based on the context words...", "B. The CBOW algorithm obtains the context information through the sliding window mechanism...", "C. In the training process of CBOW, the model averages the vectors of context words...", "D. The difference between CBOW and skip-gram is that CBOW is suitable for processing long text sequences..."], answer_set: ["A. The core idea of the CBOW algorithm is to predict the center word based on the context words...", "B. The CBOW algorithm obtains the context information through the sliding window mechanism...", "C. In the training process of CBOW, the model averages the vectors of context words..."], explanation: "A, B, and C correctly describe the CBOW model. The choice between CBOW and Skip-gram depends on factors like dataset size and word frequency, not text length." },
    { id: 51, type: 'mc', multi: true, question: "Which of the following can ModelArts ExeML object detection be used for?", options: ["A. Safety helmet detection in construction sites", "B. Text classification", "C. Housing prices forecasting", "D. Cat and dog detection in an image"], answer_set: ["A. Safety helmet detection in construction sites", "D. Cat and dog detection in an image"], explanation: "Object detection is the task of identifying and locating objects (like helmets, cats, dogs) within an image. Text classification and price forecasting are different AI tasks." },
    { id: 52, type: 'mc', multi: true, question: "When you use ModelArts ExeML to create an image classification or object detection project, what parameters must be set?", options: ["A. Project description", "B. Dataset name", "C. Input dataset path", "D. Output dataset path"], answer_set: ["B. Dataset name", "C. Input dataset path", "D. Output dataset path"], explanation: "To create a project, you must provide a name and specify the locations for the input data (source) and where the output (like labeled data or models) will be stored." },
    { id: 53, type: 'mc', multi: true, question: "Which of the following statements about the implementation of layer normalization and residual connections are true?", options: ["A. The output of each sublayer is calculated as LayerNorm(x + Sublayer(x))...", "B. Residual connections are typically implemented by adding the output of one layer directly...", "C. Layer normalization normalizes each sample's input independently...", "D. Residual connections help prevent the vanishing gradient and exploding gradient problems..."], answer_set: ["A. The output of each sublayer is calculated as LayerNorm(x + Sublayer(x))...", "C. Layer normalization normalizes each sample's input independently...", "D. Residual connections help prevent the vanishing gradient and exploding gradient problems..."], explanation: "These statements correctly describe the function and implementation of residual connections and layer normalization, which are crucial for training deep Transformer models." },
    { id: 54, type: 'mc', multi: true, question: "Which of the following are learning methods in deep learning?", options: ["A. Supervised Learning", "B. Unsupervised Learning", "C. Semi-Supervised Learning", "D. Reiforcement Learning"], answer_set: ["A. Supervised Learning", "B. Unsupervised Learning", "C. Semi-Supervised Learning", "D. Reiforcement Learning"], explanation: "These are the four main paradigms of machine learning, all of which are used in deep learning." },
    { id: 55, type: 'mc', multi: true, question: "When the neural network is training, which of following values should be multiplied with the error when the error backpropagates.", options: ["A. Derivative of activation functions", "B. Bias values", "C. Weights", "D. the value of each neuron"], answer_set: ["A. Derivative of activation functions", "C. Weights"], explanation: "During backpropagation, the error gradient is calculated by multiplying the error from the next layer by the weights of the connections and the derivative of the current layer's activation function (the chain rule)." },

    // Part 4: Fill-in-the-Blank (Questions 56-60)
    { id: 56, type: 'mc', question: "Among the three key elements of AI, (_____) sets the upper limit of model performance.", options: ["A. algorithms", "B. data", "C. computing power", "D. frameworks"], answer: "B. data", explanation: "Data quality and quantity are often the most significant limiting factors for a model's potential performance. Better algorithms and more computing power can only extract the patterns present in the data." },
    { id: 57, type: 'mc', question: "In an image preprocessing experiment, the `cv2.cvtColor(image, _____)` function is used to convert the color space of the OpenCV library to gray.", options: ["A. cv2.COLOR_RGB2GRAY", "B. cv2.COLOR_HSV2GRAY", "C. cv2.COLOR_BGR2GRAY", "D. cv2.GRAYSCALE"], answer: "C. cv2.COLOR_BGR2GRAY", explanation: "OpenCV reads images in BGR (Blue, Green, Red) format by default, so the correct conversion code is COLOR_BGR2GRAY." },
    { id: 58, type: 'mc', question: "In speech recognition, the three main problems of (_____) include evaluation, decoding, and learning (fill in the abbreviation).", options: ["A. GMM", "B. CNN", "C. HMM", "D. RNN"], answer: "C. HMM", explanation: "The three canonical problems of a Hidden Markov Model (HMM) are Evaluation, Decoding, and Learning (Training)." },
    { id: 59, type: 'mc', question: "When Support vector machine (SVM) is used for text classification, you can change the (_____) parameter in Support Vector Classifier (SVC) to adjust the penalty for incorrect classification.", options: ["A. gamma", "B. kernel", "C. C", "D. degree"], answer: "C. C", explanation: "The C parameter in SVM is the regularization parameter. It trades off correct classification of training examples against maximization of the decision function’s margin." },
    { id: 60, type: 'mc', question: "In a Transformer model, with an input word vector dimension d and no biases considered, the self-attention layer has (_____) x d x d parameters.", options: ["A. 1", "B. 2", "C. 3", "D. 4"], answer: "D. 4", explanation: "A self-attention layer has three matrices (Query, Key, Value) of size d x d, and an output projection matrix, also d x d. This gives a total of 4 * d * d parameters." }
];

